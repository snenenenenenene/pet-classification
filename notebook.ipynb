{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pet Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "It happens more often than not - especially to animal & pet lovers such as myself - that you come across the most beautiful dog while going for a walk in the park -- or whenever you're mindlessly scrolling Facebook for hours. This project is a digitalised manifestation of your gung ho dog breed connoisseur from around the corner. How? Through the means of **Machine Learning** (ML).\n",
    "The vast majority of blood, sweat and tears spent on researching and implementing the trained model will be documented by the use of the **Jupyter Notebook** you're currently reading.\n",
    "Nevertheless, to take into account the target audience and pragmatism of this implementation, I have chosen to pair the aforementioned notebook with a frontend developed in React in order to evade the convoluted process of having to manually import images into the model -- which is still an option if you're into self-loathing."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Your usual myriad of ML libraries were imported in this project such as:\n",
    "- Numpy (Arrays & matrices) \n",
    "- Pandas (Manage the arrays)\n",
    "- OS (Communication between your filesystem and python)\n",
    "- Matplotlib (Plotting graphs)\n",
    "- Tensorflow & Keras (Machine Learning)\n",
    "\n",
    "Other than these I have also imported some lesser known libraries, and modules especially, to adapt to the specific circumstances of this project. These being:\n",
    "- Preprocessing.image (Loading in images and transforming them into tensors)\n",
    "- Sklearn.metrics (Visualising & reporting the model's performance & efficiency)\n",
    "- Tensorflowjs (Exporting to a Javascript compatible model)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflowjs as tfjs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to adhere to coding conventions and to avoid confusion further on in the project I have tactically split up the setup part of my code in order clarify some decisions I've made that other developers might not inherently also chose to do.\n",
    "The most notable section is the mapping section where I list every breed conform to the alphabetically stored folders with their correspondent names."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "TRAIN = 'breeds/TRAIN'\n",
    "TEST = 'breeds/TEST'\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "EPOCH_CNT = 3\n",
    "\n",
    "dataset=[] \n",
    "name=[]\n",
    "count=0\n",
    "pet_dict=[]\n",
    "\n",
    "for file in os.listdir(TRAIN):\n",
    "    pet_dict+=[file]\n",
    "\n",
    "mapping={\n",
    "\t\"japanese_chin\": 0,\n",
    "\t\"keeshond\": 1,\n",
    "\t\"bombay\": 2,\n",
    "\t\"egyptian_mau\": 3,\n",
    "\t\"american_pit_bull_terrier\": 4,\n",
    "\t\"pug\": 5,\n",
    "\t\"bengal\": 6,\n",
    "\t\"leonberger\": 7,\n",
    "\t\"abyssinian\": 8,\n",
    "\t\"persian\": 9,\n",
    "\t\"siamese\": 10,\n",
    "\t\"british_shorthair\": 11,\n",
    "\t\"boxer\": 12,\n",
    "\t\"newfoundland\": 13,\n",
    "\t\"staffordshire_bull_terrier\": 14,\n",
    "\t\"german_shorthaired\": 15,\n",
    "\t\"pomeranian\": 16,\n",
    "\t\"american_bulldog\": 17,\n",
    "\t\"birman\": 18,\n",
    "\t\"russian_blue\": 19,\n",
    "\t\"miniature_pinscher\": 20,\n",
    "\t\"shiba_inu\": 21,\n",
    "\t\"english_setter\": 22,\n",
    "\t\"ragdoll\": 23,\n",
    "\t\"chihuahua\": 24,\n",
    "\t\"basset_hound\": 25,\n",
    "\t\"saint_bernard\": 26,\n",
    "\t\"scottish_terrier\": 27,\n",
    "\t\"sphynx\": 28,\n",
    "\t\"maine_coon\": 29,\n",
    "\t\"great_pyrenees\": 30,\n",
    "\t\"beagle\": 31,\n",
    "\t\"yorkshire_terrier\": 32,\n",
    "\t\"wheaten_terrier\": 33,\n",
    "\t\"samoyed\": 34,\n",
    "\t\"english_cocker_spaniel\": 35,\n",
    "\t\"havanese\": 36,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning & Processing\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As this project is almost entirely image based there quite simply isn't a lot of cleaning, imputation or processing to be done."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "for file in os.listdir(TRAIN):\n",
    "    path=os.path.join(TRAIN,file)\n",
    "    for im in os.listdir(path):\n",
    "        image=load_img(os.path.join(path,im), grayscale=False, color_mode='rgb', target_size=(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
    "        image=img_to_array(image)\n",
    "        image=image/255.0\n",
    "        dataset.append([image,count])     \n",
    "    count=count+1\n",
    "test=[]\n",
    "testfile=[]\n",
    "\n",
    "for file in os.listdir(TEST):\n",
    "    path=os.path.join(TEST,file)\n",
    "    image=load_img(path, grayscale=False, color_mode='rgb', target_size=(IMAGE_HEIGHT,IMAGE_WIDTH))\n",
    "    image=img_to_array(image)\n",
    "    image=image/255.0\n",
    "    test+=[image]\n",
    "    testfile+=[file]\n",
    "data,labels0=zip(*dataset)\n",
    "labels1=to_categorical(labels0)\n",
    "labels=np.array(labels1)\n",
    "data=np.array(data)\n",
    "test=np.array(test)\n",
    "data2=data.reshape(-1,IMAGE_HEIGHT,IMAGE_WIDTH,3)\n",
    "test2=test.reshape(-1,IMAGE_HEIGHT,IMAGE_WIDTH,3)\n",
    "trainx,testx,trainy,testy=train_test_split(data,labels,test_size=0.2,random_state=44)\n",
    "print(trainx.shape)\n",
    "print(testx.shape)\n",
    "print(trainy.shape)\n",
    "print(testy.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4712, 256, 256, 3)\n",
      "(1178, 256, 256, 3)\n",
      "(4712, 37)\n",
      "(1178, 37)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to actually train the algorithm we'll make use of [**Densely Connected Convolutional Networks**](https://arxiv.org/abs/1608.06993) (DCCN). To go about this in a comprehensive and easy to use manner, we'll be implementing said DCCN using a Keras module which we've imported in one of the former stages of this document. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True, rotation_range=20, zoom_range=0.2,\n",
    "                             width_shift_range=0.2, height_shift_range=0.2, shear_range=0.1, fill_mode=\"nearest\")\n",
    "\n",
    "pretrained_model = tf.keras.applications.DenseNet121(input_shape=(\n",
    "    IMAGE_HEIGHT, IMAGE_WIDTH, 3), include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "inputs = pretrained_model.input\n",
    "x3 = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
    "outputs = tf.keras.layers.Dense(37, activation='softmax')(x3)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "his = model.fit(datagen.flow(trainx, trainy, batch_size=32),\n",
    "                validation_data=(testx, testy), epochs=EPOCH_CNT)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "148/148 [==============================] - 363s 2s/step - loss: 2.1823 - accuracy: 0.4213 - val_loss: 0.8098 - val_accuracy: 0.7733\n",
      "Epoch 2/3\n",
      "148/148 [==============================] - 412s 3s/step - loss: 1.0581 - accuracy: 0.6891 - val_loss: 0.5222 - val_accuracy: 0.8362\n",
      "Epoch 3/3\n",
      " 53/148 [=========>....................] - ETA: 3:27 - loss: 0.8569 - accuracy: 0.7321"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b8007a425ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m his = model.fit(datagen.flow(trainx, trainy, batch_size=32),\n\u001b[0m\u001b[1;32m     18\u001b[0m                 validation_data=(testx, testy), epochs=EPOCH_CNT)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Fitness\n",
    "\n",
    "In order to fathom the efficiency and as to how our newly born model performs we will be using a couple of built-in modules and functions from the Sklearn package. \n",
    "Previously the trained model is stored in the \"his\" variable. After going through the various learning cycles its accuracy and loss data are then stored in sepperate new variables and are then plotted in the next section. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = model.predict(testx)\n",
    "pred = np.argmax(y_pred, axis=1)\n",
    "ground = np.argmax(testy, axis=1)\n",
    "print(classification_report(ground, pred))\n",
    "\n",
    "get_acc = his.history['accuracy']\n",
    "value_acc = his.history['val_accuracy']\n",
    "get_loss = his.history['loss']\n",
    "validation_loss = his.history['val_loss']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs = range(len(get_acc))\n",
    "plt.plot(epochs, get_acc, 'r', label='Accuracy of Training data')\n",
    "plt.plot(epochs, value_acc, 'b', label='Accuracy of Validation data')\n",
    "plt.title('Training vs validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loss"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epochs = range(len(get_loss))\n",
    "plt.plot(epochs, get_loss, 'r', label='Loss of Training data')\n",
    "plt.plot(epochs, validation_loss, 'b', label='Loss of Validation data')\n",
    "plt.title('Training vs validation loss')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Proof testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This section is quite possibly the most gratifying part of this entire project. Sometimes at least. \n",
    "Firstly, we declare the reverse mapping of breeds (see #Setup) to then map the different representations of breeds - using integers - to their respective indeces. A random is then loaded in and passed to the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reverse_mapping={\n",
    "    0: \"abyssinian\",\n",
    "    1: \"american_bulldog\",\n",
    "    2: \"american_pit_bull_terrier\",\n",
    "    3: \"basset_hound\",\n",
    "    4: \"beagle\",\n",
    "    5: \"bengal\",\n",
    "    6: \"birman\",\n",
    "    7: \"bombay\",\n",
    "    8: \"boxer\",\n",
    "    9: \"british_shorthair\",\n",
    "    10: \"chihuahua\",\n",
    "    11: \"egyptian_mau\",\n",
    "    12: \"english_cocker_spaniel\",\n",
    "    13: \"english_setter\",\n",
    "    14: \"german_shorthaired\",\n",
    "    15: \"great_pyrenees\",\n",
    "    16: \"havanese\",\n",
    "    17: \"japanese_chin\",\n",
    "    18: \"keeshond\",\n",
    "    19: \"leonberger\",\n",
    "    20: \"maine_coon\",\n",
    "    21: \"miniature_pinscher\",\n",
    "    22: \"newfoundland\",\n",
    "    23: \"persian\",\n",
    "    24: \"pomeranian\",\n",
    "    25: \"pug\",\n",
    "    26: \"ragdoll\",\n",
    "    27: \"russian_blue\",\n",
    "    28: \"saint_bernard\",\n",
    "    29: \"samoyed\",\n",
    "    30: \"scottish_terrier\",\n",
    "    31: \"shiba_inu\",\n",
    "    32: \"siamese\",\n",
    "    33: \"sphynx\",\n",
    "    34: \"staffordshire_bull_terrier\",\n",
    "    35: \"wheaten_terrier\",\n",
    "    36: \"yorkshire_terrier\",\n",
    "  }\n",
    "\n",
    "image=load_img(\"breeds/TEST/1002.jpg\",target_size=(256,256))\n",
    "image\n",
    "\n",
    "# model = keras.models.load_model('models/model1.h5')\n",
    "\n",
    "\n",
    "image=img_to_array(image) \n",
    "image=image/255.0\n",
    "prediction_image=np.array(image)\n",
    "prediction_image= np.expand_dims(image, axis=0)\n",
    "\n",
    "def mapper(value):\n",
    "    return reverse_mapping[value]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# PREDICTION\n",
    "print(prediction_image)\n",
    "prediction=model.predict(prediction_image)\n",
    "value=np.argmax(prediction)\n",
    "move_name=mapper(value)\n",
    "print(f\"Prediction is {format(move_name).capitalize()}.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Serialisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to make use of the functionality of the model it will be serialised as well as converted into a model which is able to be interpreted by the aforementioned React app. The TensorflowJS converter module will split up the model into one model.json as well as various weight files which will add their respective weights to the breeds. After this is done and dusted it is ready to be pushed straight to github in order for the raw model.json file to receive GET-requests."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Uncomment to save model & to export it to a tsjs compatible format.\n",
    "\n",
    "model.save('models/model1.h5')\n",
    "tfjs.converters.save_keras_model(model, 'models/tfjs')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bronvermelding"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}